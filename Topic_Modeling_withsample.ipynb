{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ2uomNYHAPysXMeNKQW5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiran597/statistics_analysis/blob/main/Topic_Modeling_withsample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling:\n",
        "- Topic modeling is a machine learning technique that automatically analyzes text data to determine cluster words for a set of documents."
      ],
      "metadata": {
        "id": "rRgdbrk7SyvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOuvnkAlGkeD",
        "outputId": "3c4face1-18ec-44e1-ab85-29cf5ebf07c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "## Load function, Update Environment\n",
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install numpy\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install sklearn\n",
        "from sklearn import metrics\n",
        "\n",
        "!{sys.executable} -m pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "!{sys.executable} -m pip install nltk\n",
        "import nltk\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "from pprint import pprint\n",
        "!{sys.executable} -m pip install pyLDAvis #visualizing LDA\n",
        "import pyLDAvis\n",
        "import pyLDAvis.lda_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to My Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23iV-R0AS_c6",
        "outputId": "b63d5d12-f028-46bd-86da-578c078265eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text normalization function\n",
        "%run \"/content/drive/MyDrive/lilysilk/Text_Normalization_Function.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoxQryhJTDMx",
        "outputId": "a2ceb638-95d1-48c7-9566-7366ef3c84d2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html.parser in /usr/local/lib/python3.11/dist-packages (0.2)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (from html.parser) (3.11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pattern3 in /usr/local/lib/python3.11/dist-packages (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from pattern3) (4.13.3)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.11/dist-packages (from pattern3) (18.10.0)\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.11/dist-packages (from pattern3) (0.2.4)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (from pattern3) (6.0.11)\n",
            "Requirement already satisfied: pdfminer3k in /usr/local/lib/python3.11/dist-packages (from pattern3) (1.3.4)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from pattern3) (3.20.1)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (from pattern3) (20240706)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->pattern3) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->pattern3) (4.12.2)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.11/dist-packages (from cherrypy->pattern3) (10.0.1)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from cherrypy->pattern3) (3.2.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from cherrypy->pattern3) (10.6.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.11/dist-packages (from cherrypy->pattern3) (3.0.post1)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.11/dist-packages (from cherrypy->pattern3) (5.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx->pattern3) (5.3.1)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx->pattern3) (11.1.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser->pattern3) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->pattern3) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->pattern3) (43.0.3)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (from pdfminer3k->pattern3) (3.11)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.11/dist-packages (from cheroot>=8.2.1->cherrypy->pattern3) (4.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern3) (1.17.1)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.11/dist-packages (from portend>=2.1.1->cherrypy->pattern3) (5.8.0)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.11/dist-packages (from jaraco.collections->cherrypy->pattern3) (4.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zc.lockfile->cherrypy->pattern3) (75.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern3) (2.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2.8.2)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.11/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (6.0.1)\n",
            "Requirement already satisfied: autocommand in /usr/local/lib/python3.11/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (2.2.2)\n",
            "Requirement already satisfied: backports.tarfile in /usr/local/lib/python3.11/dist-packages (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->pattern3) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (1.17.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
            "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
            "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "videoreview = pd.read_csv('/content/drive/MyDrive/lilysilk/Data/translated_comments_emoji (1).csv')"
      ],
      "metadata": {
        "id": "SDkmZHvATFIr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videoreview['like_count'] = pd.to_numeric(videoreview['like_count'], errors='coerce')  # 如果无法转换，会变成 NaN\n",
        "videoreview['likes'] = pd.to_numeric(videoreview['likes'], errors='coerce')  # 同样的处理\n",
        "# 然后进行加法操作\n",
        "videoreview['total_likes'] = videoreview.groupby('publish_number')['like_count'].transform('sum') + videoreview['likes']\n",
        "videoreview['representative_comment_likes'] = videoreview['like_count'] + videoreview['likes']"
      ],
      "metadata": {
        "id": "KV_X4AaSTIip"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## new dataframe with only publish_number, published_at, total_likes\n",
        "videolike = videoreview.groupby('publish_number').agg(\n",
        "    total_video_likes=('total_likes','max'),\n",
        "    published_at=('published_at', 'first')  # 保留每个视频的第一个 published_at\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "bXlGpO08TMfx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videoreview['text_column'] = videoreview['text_column'].fillna('')\n",
        "videoreview = videoreview.dropna(subset=['text_column'])"
      ],
      "metadata": {
        "id": "vvFmSAOMWIxR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Corpus"
      ],
      "metadata": {
        "id": "oeA5HVt4TRzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = videoreview.text_column # X\n",
        "likes = videoreview.representative_comment_likes # Y"
      ],
      "metadata": {
        "id": "qiF3X8K-TQTQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('Review.pickle','wb') as f:\n",
        "    pickle.dump(reviews,f)\n",
        "\n",
        "with open('sent.pickle','wb') as f:\n",
        "    pickle.dump(likes,f)"
      ],
      "metadata": {
        "id": "Vl7C3AqJTcZt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_in = open('Review.pickle','rb')\n",
        "likes_in = open('sent.pickle','rb')\n",
        "reviews = pickle.load(reviews_in)\n",
        "likes = pickle.load(likes_in)"
      ],
      "metadata": {
        "id": "kTOxWg9bTc7V"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "reviews_corpus = []\n",
        "for i in range(0, len(reviews)):\n",
        "    review = re.sub(r'\\W', ' ', str(reviews[i]))\n",
        "    review = review.lower()\n",
        "    review = re.sub(r'^br$', ' ', review)\n",
        "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
        "    review = re.sub(r'^[a-z]\\s+', '', review)\n",
        "    review = re.sub(r'\\s+', ' ', review)\n",
        "    reviews_corpus.append(review)"
      ],
      "metadata": {
        "id": "qQUwWamtTglr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the reviews\n",
        "NORM_reviews = normalize_corpus(videoreview.text_column)"
      ],
      "metadata": {
        "id": "mGy2ADt1Tid_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vectorizer = CountVectorizer(max_features=1000)\n",
        "bow_a_corpus = bow_vectorizer.fit_transform(NORM_reviews)"
      ],
      "metadata": {
        "id": "o9S1mTsHTrzA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA Analysis:"
      ],
      "metadata": {
        "id": "NUG0OA0vTwGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_reviews = LatentDirichletAllocation(n_components=4, max_iter=100,\n",
        "                                     doc_topic_prior = 0.25,\n",
        "                                     topic_word_prior = 0.25).fit(bow_a_corpus)"
      ],
      "metadata": {
        "id": "bgpMhLy0TuJ8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (topic_idx))\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "def get_topic_words(vectorizer, lda_model, n_words):\n",
        "    keywords = np.array(vectorizer.get_feature_names_out())\n",
        "    topic_words = []\n",
        "    for topic_weights in lda_model.components_:\n",
        "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
        "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
        "    return topic_words"
      ],
      "metadata": {
        "id": "N9LmeG3jTzkw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words_news = 10\n",
        "display_topics(lda_reviews, bow_vectorizer.get_feature_names_out(), no_top_words_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO96YtdPUEZo",
        "outputId": "7a30e829-199f-4baf-d360-47993d331379"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "love happy video great thank birthday thanks beautiful look lovely\n",
            "Topic 1:\n",
            "like good really use think time want need year work\n",
            "Topic 2:\n",
            "hair love look video old style new money please always\n",
            "Topic 3:\n",
            "love look dress silk wear outfit white beautiful bag shirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = lda_reviews.components_ / lda_reviews.components_.sum(axis=1)[:, np.newaxis]\n",
        "word_weights_df = pd.DataFrame(word_weights.T,\n",
        "                               index = bow_vectorizer.get_feature_names_out(),\n",
        "                               columns = [\"Topic_\" + str(i) for i in range(4)])"
      ],
      "metadata": {
        "id": "TqRkvgBkUGcS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_weights_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ykacCPPblGV",
        "outputId": "252df2fe-913d-485b-f48d-60846d77d79f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Topic_0   Topic_1   Topic_2   Topic_3\n",
            "14k         0.000014  0.000009  0.003229  0.000010\n",
            "able        0.000014  0.001465  0.001169  0.000010\n",
            "absolutely  0.002891  0.000009  0.003773  0.003853\n",
            "accessory   0.000013  0.000009  0.000015  0.002283\n",
            "actually    0.000014  0.003143  0.000889  0.000010\n",
            "ad          0.000014  0.000270  0.000015  0.000602\n",
            "add         0.000014  0.002385  0.000015  0.001074\n",
            "addition    0.000234  0.000177  0.000338  0.000171\n",
            "adorable    0.001855  0.000009  0.000014  0.000010\n",
            "adore       0.001761  0.000009  0.000402  0.000316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_weights_df.sort_values(by='Topic_0',ascending=False).head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiZ6tCiDbd4F",
        "outputId": "bdc9ddca-1a96-45ad-89e6-2c1e408b6ce8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Topic_0   Topic_1   Topic_2   Topic_3\n",
            "love       0.060560  0.000009  0.045844  0.053817\n",
            "happy      0.038358  0.000009  0.000014  0.000010\n",
            "video      0.038241  0.007471  0.019480  0.007042\n",
            "great      0.030248  0.005290  0.005458  0.007808\n",
            "thank      0.029937  0.000141  0.008335  0.005581\n",
            "birthday   0.024400  0.000009  0.000014  0.000010\n",
            "thanks     0.022758  0.000009  0.000015  0.001981\n",
            "beautiful  0.022692  0.000009  0.011214  0.018158\n",
            "look       0.021603  0.004029  0.024897  0.037112\n",
            "lovely     0.019408  0.000009  0.002822  0.000010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting tools\n",
        "from pprint import pprint\n",
        "!{sys.executable} -m pip install pyLDAvis #visualizing LDA\n",
        "import pyLDAvis\n",
        "import pyLDAvis.lda_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTDpa5ysUL4_",
        "outputId": "24694b18-9fbd-418f-de2b-2512f2761019"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import  CountVectorizer #bag-of-words vectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation #package for LDA"
      ],
      "metadata": {
        "id": "_RkCqXCwUOOu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"pandas<2.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "9SjlobyQUO8i",
        "outputId": "55fa4fa6-095e-42e9-a7f9-320d18ca33d5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas<2.0.0\n",
            "  Using cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0.0) (2025.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0.0) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0) (1.17.0)\n",
            "Using cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "de5809f7292442d7be34b57d9b7b4c31"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare to display result in the Jupyter notebook\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
        "pyLDAvis.lda_model.prepare(lda_reviews, bow_a_corpus, bow_vectorizer, mds='tsne')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "n_DD4B-yURdP",
        "outputId": "90271b93-2c83-4412-bdf0-24481d9ff15c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
              "topic                                                  \n",
              "1      23.649176  39.346947       1        1  31.778801\n",
              "3      22.816502 -82.820076       2        1  27.955159\n",
              "0      83.586288 -22.170952       3        1  20.482728\n",
              "2     -36.886395 -21.235706       4        1  19.783312, topic_info=      Term         Freq        Total Category  logprob  loglift\n",
              "368   hair   959.000000   959.000000  Default  30.0000  30.0000\n",
              "523   love  3317.000000  3317.000000  Default  29.0000  29.0000\n",
              "239  dress   901.000000   901.000000  Default  28.0000  28.0000\n",
              "783   silk   900.000000   900.000000  Default  27.0000  27.0000\n",
              "377  happy   714.000000   714.000000  Default  26.0000  26.0000\n",
              "..     ...          ...          ...      ...      ...      ...\n",
              "876  thank   149.793737   852.624901   Topic4  -4.7873  -0.1187\n",
              "497   like   161.772052  1238.369121   Topic4  -4.7104  -0.4150\n",
              "883  think   128.601773   542.545229   Topic4  -4.9398   0.1808\n",
              "882  thing   108.185345   315.226284   Topic4  -5.1127   0.5509\n",
              "354   good   113.319361   805.063460   Topic4  -5.0663  -0.3404\n",
              "\n",
              "[251 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "0         4  0.986498        14k\n",
              "10        3  0.981613  adventure\n",
              "19        3  0.980096        ali\n",
              "23        3  0.977582      along\n",
              "26        1  0.119209     always\n",
              "...     ...       ...        ...\n",
              "988       4  0.216158         xx\n",
              "991       1  0.831369       year\n",
              "991       4  0.166849       year\n",
              "997       2  0.057293    youtube\n",
              "997       4  0.931016    youtube\n",
              "\n",
              "[311 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 4, 1, 3])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el33501382569467599362910955856\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el33501382569467599362910955856_data = {\"mdsDat\": {\"x\": [23.6491756439209, 22.81650161743164, 83.58628845214844, -36.88639450073242], \"y\": [39.346946716308594, -82.82007598876953, -22.17095184326172, -21.235706329345703], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [31.778800622526404, 27.95515934271597, 20.48272759246953, 19.783312442288096]}, \"tinfo\": {\"Term\": [\"hair\", \"love\", \"dress\", \"silk\", \"happy\", \"wear\", \"outfit\", \"birthday\", \"white\", \"thanks\", \"thank\", \"old\", \"video\", \"bag\", \"lovely\", \"shirt\", \"share\", \"lilysilk\", \"style\", \"money\", \"beautiful\", \"look\", \"great\", \"black\", \"top\", \"http\", \"navy\", \"wonderful\", \"lydia\", \"like\", \"skin\", \"eat\", \"recommend\", \"need\", \"eye\", \"makeup\", \"dry\", \"month\", \"water\", \"foundation\", \"talk\", \"body\", \"diet\", \"etc\", \"sleep\", \"lose\", \"clean\", \"dog\", \"learn\", \"free\", \"move\", \"plant\", \"enough\", \"hand\", \"issue\", \"check\", \"coffee\", \"sell\", \"fall\", \"side\", \"work\", \"put\", \"end\", \"year\", \"product\", \"use\", \"right\", \"want\", \"like\", \"even\", \"girl\", \"good\", \"time\", \"think\", \"buy\", \"feel\", \"really\", \"dont\", \"thing\", \"live\", \"keep\", \"different\", \"people\", \"know\", \"im\", \"every\", \"day\", \"lot\", \"much\", \"could\", \"video\", \"well\", \"take\", \"clothes\", \"great\", \"dress\", \"silk\", \"wear\", \"outfit\", \"white\", \"bag\", \"shirt\", \"lilysilk\", \"http\", \"black\", \"top\", \"navy\", \"pant\", \"lily\", \"blue\", \"size\", \"skirt\", \"elegant\", \"classic\", \"shoe\", \"link\", \"blouse\", \"striped\", \"belt\", \"com\", \"summer\", \"jean\", \"trouser\", \"chic\", \"knit\", \"mel\", \"hermes\", \"piece\", \"look\", \"love\", \"favorite\", \"beautiful\", \"color\", \"gorgeous\", \"style\", \"like\", \"great\", \"always\", \"video\", \"happy\", \"birthday\", \"lydia\", \"fun\", \"mother\", \"vlog\", \"stephanie\", \"dubai\", \"jo\", \"trip\", \"gerry\", \"michael\", \"irene\", \"gerald\", \"congrats\", \"wonderful\", \"chicken\", \"interview\", \"smile\", \"adventure\", \"chari\", \"holiday\", \"sunday\", \"weekend\", \"ali\", \"easter\", \"podcast\", \"myrtle\", \"along\", \"joy\", \"thanks\", \"lovely\", \"share\", \"gift\", \"amazing\", \"sweet\", \"thank\", \"enjoy\", \"great\", \"xx\", \"video\", \"day\", \"love\", \"cute\", \"hello\", \"beautiful\", \"wow\", \"watch\", \"wait\", \"hope\", \"look\", \"much\", \"always\", \"us\", \"hair\", \"old\", \"money\", \"sorry\", \"happen\", \"recommendation\", \"luxury\", \"story\", \"helen\", \"heidi\", \"comment\", \"purple\", \"14k\", \"london\", \"bleach\", \"ur\", \"inspire\", \"blonde\", \"break\", \"quiet\", \"videos\", \"k18\", \"olaplex\", \"salon\", \"whatever\", \"edit\", \"energy\", \"victoria\", \"hairdresser\", \"safe\", \"youtube\", \"experience\", \"please\", \"cut\", \"style\", \"channel\", \"fashion\", \"new\", \"know\", \"love\", \"im\", \"look\", \"always\", \"video\", \"watch\", \"color\", \"way\", \"us\", \"take\", \"well\", \"much\", \"beautiful\", \"give\", \"thank\", \"like\", \"think\", \"thing\", \"good\"], \"Freq\": [959.0, 3317.0, 901.0, 900.0, 714.0, 733.0, 618.0, 454.0, 491.0, 474.0, 852.0, 347.0, 1456.0, 415.0, 412.0, 387.0, 404.0, 367.0, 555.0, 286.0, 1085.0, 1908.0, 1011.0, 321.0, 321.0, 316.0, 309.0, 246.0, 239.0, 1238.0, 142.65718421923123, 130.80424062128597, 134.73728154006292, 297.9965972763788, 126.81364858791937, 120.87901344850519, 99.14361187666498, 98.14763469422161, 91.2369644240101, 91.2300189500178, 91.20478201543658, 89.24096294709561, 74.42677882254829, 76.37287696450888, 70.46275845399208, 70.44825975678798, 68.48243399760067, 61.550266609873574, 61.545554337841274, 59.570445603047546, 58.57749164989398, 55.628261392177, 56.60367208195398, 56.59351686468282, 55.615405836760246, 54.62209454209981, 54.62193208831986, 51.64934791905942, 52.62148119417451, 49.67347812174872, 287.5328038161715, 158.53481202186515, 93.31086547156853, 289.18194075257503, 177.0601049469041, 381.51549943661473, 129.9944172899509, 313.5585033036234, 795.119055607473, 189.28529973078116, 126.69884727500025, 498.6467344519505, 333.72129757634866, 349.668529432672, 286.6633098018841, 239.17662955137345, 414.52951407913594, 152.30275149745296, 206.52642837565165, 122.95223867340066, 151.33709009605724, 137.12472111601227, 169.0191097353591, 207.16109591355456, 208.69741482989525, 154.0158155861752, 195.36356041993756, 156.5599027578754, 193.33584371853328, 147.1948266206744, 215.6739732734184, 171.95618597630443, 155.49371760209849, 148.7896696138805, 152.72052211052497, 900.5446405853161, 899.5637810396975, 733.185090371362, 617.7296488663133, 490.51119563714104, 415.150922664659, 386.78361894693023, 367.20296221192876, 315.3506354384563, 321.2050491072952, 321.1951580639821, 308.4984372030371, 244.88760501449258, 226.28643526856888, 224.33499720813145, 225.30221931991042, 179.3155905296169, 170.49698928820197, 161.68708844936498, 152.88750646233999, 151.90003078456613, 147.01434290870057, 136.2644897820866, 134.30568283961162, 127.4575134800544, 127.43093421041476, 123.53876404495598, 116.68865639307045, 115.70172620440462, 108.85584945397339, 155.3983936231429, 145.45364296338602, 228.15663631530882, 942.4583223624326, 1366.7048502686148, 191.2234516033371, 461.11697717147644, 263.19018150119183, 203.96766070254827, 249.63175485399992, 281.2147702964901, 198.29186768159104, 173.41785157095208, 178.82583458807326, 713.734972509612, 454.0206292138726, 238.38990406582764, 204.06537363894057, 193.28219558741418, 177.62769545088065, 131.56311638901772, 130.58402476053462, 133.50704908166634, 117.83264165688686, 98.24670716607126, 81.58029238761934, 74.72094692719368, 71.7865823960374, 74.69257276435282, 243.48264701061976, 61.979853858544374, 62.94112058050758, 55.09983256722207, 51.19918688331731, 52.162064838868815, 52.157094299497295, 51.18667337130171, 50.20707998924489, 49.237864432566056, 49.23433254110904, 46.293092831821994, 45.31869565997977, 46.280981316270676, 43.3518161237496, 423.4617464349929, 361.1210496627218, 343.70930316891, 76.34958990261002, 164.25538985411617, 69.73394216765595, 557.0361818377926, 236.09453947114514, 562.8257782983819, 126.17014762035525, 711.5490606513913, 299.3884796709931, 1126.8417558654926, 142.76841660271197, 103.46143426146155, 422.2295179540042, 124.36452735694813, 207.51488287043577, 114.04709923310611, 152.11971805007158, 401.96410922309815, 215.63968579648798, 161.52255125997377, 135.5277141671545, 958.5680105768483, 347.0509255813685, 286.21347756525233, 147.2846090324693, 138.15621668607298, 91.47443542364014, 86.42983350694038, 81.36033611473685, 80.35017049879214, 76.3072951049601, 75.2664079801685, 71.21342927275697, 58.03816564749016, 57.00526920082487, 53.99594986423451, 54.988964415551095, 53.97270829971276, 49.93881057605655, 50.92532459208707, 44.851976978975884, 39.77142725101735, 34.72443347607128, 34.7235426278068, 33.70923232210043, 34.699560262847974, 33.677424201706884, 33.65741081784076, 30.662867944967886, 29.654849866964597, 31.599203103785587, 65.39591301218323, 84.77223286288178, 219.41521194011838, 64.42090978230375, 305.6440746698118, 118.74798220292388, 127.515968862628, 295.6768698287288, 215.0310994185012, 823.8882362286829, 194.1256506163574, 447.4476847945846, 218.8200980051047, 350.0886726589913, 174.12397653417565, 166.85506414159494, 134.88849496578507, 138.12929696890873, 135.87868661990677, 159.56723477704327, 161.77474886710118, 201.53774040359139, 112.83794780654713, 149.79373688969744, 161.7720519626777, 128.60177327847921, 108.18534481268007, 113.31936122492093], \"Total\": [959.0, 3317.0, 901.0, 900.0, 714.0, 733.0, 618.0, 454.0, 491.0, 474.0, 852.0, 347.0, 1456.0, 415.0, 412.0, 387.0, 404.0, 367.0, 555.0, 286.0, 1085.0, 1908.0, 1011.0, 321.0, 321.0, 316.0, 309.0, 246.0, 239.0, 1238.0, 143.42676988235897, 131.55701558400108, 135.51359504634613, 299.73427750913714, 127.60046160094345, 121.66560630112977, 99.9046683320494, 98.91562630317509, 91.99138423574813, 91.99135916259958, 91.9916623897981, 90.01302929686521, 75.1760425407914, 77.15438313171653, 71.21945855796662, 71.21970028373957, 69.24116739168359, 62.317089530618894, 62.31746422022697, 60.338993146948816, 59.349672159640704, 56.38228445357879, 57.371470605104875, 57.37143339360614, 56.382283930320234, 55.39320427610965, 55.393198799933465, 52.42581615178075, 53.41526088953718, 50.44753293784875, 322.30853891031825, 173.9328073818448, 100.05134134011479, 347.6195614766832, 203.3056603893493, 483.7048877612938, 147.80246817405327, 402.7452996778244, 1238.3691207524214, 238.58971179404605, 148.15039590280065, 805.063460435126, 494.6279721110661, 542.5452291638172, 428.7571678716199, 351.0171590409569, 734.96527603753, 196.9308647846217, 315.22628400468426, 151.02226946880305, 214.19477409799515, 181.63810303478286, 270.5385021735714, 422.7053896022917, 448.41269415917816, 251.9612436655678, 536.3416289026258, 278.8695846978763, 606.955203517745, 246.0975667220345, 1456.1375411718743, 530.1793249800119, 360.7723080173459, 264.84027613937957, 1011.9197567784938, 901.3156162696918, 900.3370852115646, 733.9730815365846, 618.4961353629167, 491.2764398237381, 415.92317813066603, 387.5431998572871, 367.9710049022168, 316.1042845813428, 321.9763376042882, 321.97653292978725, 309.254006926861, 245.6441225187442, 227.0505243281534, 225.0932512377242, 226.07202648750103, 180.07708704038177, 171.2697853837681, 162.46254071020675, 153.65456085049465, 152.67609170298434, 147.7828809592898, 137.01789227387906, 135.0607281185601, 128.21039272719358, 128.21072255911392, 124.29601203129057, 117.44570123161931, 116.46724070928244, 109.61677172266224, 156.59084721549465, 148.76519720927092, 269.5744088825974, 1908.184042021459, 3317.6962223820065, 247.94442800470256, 1085.1452867395262, 430.56102131983005, 333.376661249135, 555.7877103314958, 1238.3691207524214, 1011.9197567784938, 629.1445233164684, 1456.1375411718743, 714.4952422669215, 454.7716521063567, 239.1523363387517, 204.84949577982934, 194.06823143199617, 178.38674113177026, 132.32262874243267, 131.34250837303267, 134.28293951976866, 118.60140712141174, 98.99949888283585, 82.33805767073302, 75.47731476483456, 72.53705177377797, 75.47757431612418, 246.07379375052622, 62.73618700191918, 63.71671820956562, 55.87604603714883, 51.955317533408035, 52.93529783232751, 52.935746298973775, 51.955366106997744, 50.97524713364707, 49.995094936112174, 49.99505637493249, 47.05489295333876, 46.07465360005096, 47.05486697214331, 44.11461138608806, 474.29835960077537, 412.3604913515253, 404.8517240281084, 82.33030113743978, 196.0900898056436, 74.53453862386014, 852.6249014149533, 323.73395282816523, 1011.9197567784938, 161.9182721437184, 1456.1375411718743, 536.3416289026258, 3317.6962223820065, 200.84251884608057, 131.26891507405634, 1085.1452867395262, 186.31924686853313, 451.4368697814727, 161.20461364721464, 276.87414855397236, 1908.184042021459, 606.955203517745, 629.1445233164684, 342.4101068505798, 959.3188753720102, 347.81347623173167, 286.9674770321751, 148.03524542743693, 138.90828055263705, 92.25839954174074, 87.18870184145344, 82.11821420916388, 81.10417202158253, 77.0482232323729, 76.03331426849532, 71.97690630716549, 58.79383783428598, 57.779159754846766, 54.7378912639338, 55.751283710565836, 54.73715148099548, 50.68145670846308, 51.694760581298354, 45.610428087826016, 40.539586237253324, 35.46982751452705, 35.46980314797309, 34.45568405833841, 35.4690628054287, 34.45462184087302, 34.454147485130946, 31.413202874062897, 30.399326166755642, 32.42483417920842, 69.81616712495705, 96.0501315464034, 338.4535200550488, 76.63239486697461, 555.7877103314958, 169.62012174812847, 186.54383831546807, 560.4970367375092, 422.7053896022917, 3317.6962223820065, 448.41269415917816, 1908.184042021459, 629.1445233164684, 1456.1375411718743, 451.4368697814727, 430.56102131983005, 293.4113333883986, 342.4101068505798, 360.7723080173459, 530.1793249800119, 606.955203517745, 1085.1452867395262, 250.05749730192036, 852.6249014149533, 1238.3691207524214, 542.5452291638172, 315.22628400468426, 805.063460435126], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3101, -5.3968, -5.3672, -4.5734, -5.4278, -5.4757, -5.6739, -5.684, -5.7571, -5.7571, -5.7574, -5.7792, -5.9607, -5.9349, -6.0154, -6.0156, -6.0439, -6.1507, -6.1507, -6.1834, -6.2002, -6.2518, -6.2344, -6.2346, -6.2521, -6.2701, -6.2701, -6.326, -6.3074, -6.365, -4.6092, -5.2045, -5.7346, -4.6035, -5.094, -4.3264, -5.403, -4.5225, -3.592, -5.0273, -5.4287, -4.0586, -4.4602, -4.4135, -4.6122, -4.7933, -4.2434, -5.2446, -4.9401, -5.4587, -5.251, -5.3496, -5.1405, -4.937, -4.9296, -5.2335, -4.9957, -5.2171, -5.0061, -5.2788, -4.8967, -5.1233, -5.2239, -5.268, -5.2419, -3.3393, -3.3404, -3.5449, -3.7163, -3.9469, -4.1137, -4.1845, -4.2364, -4.3886, -4.3702, -4.3703, -4.4106, -4.6415, -4.7205, -4.7292, -4.7249, -4.9532, -5.0036, -5.0567, -5.1126, -5.1191, -5.1518, -5.2277, -5.2422, -5.2945, -5.2947, -5.3258, -5.3828, -5.3913, -5.4523, -5.0963, -5.1625, -4.7123, -3.2938, -2.9222, -4.8889, -4.0087, -4.5694, -4.8244, -4.6223, -4.5032, -4.8526, -4.9866, -4.9559, -3.2608, -3.7132, -4.3574, -4.5129, -4.5671, -4.6516, -4.9518, -4.9593, -4.9371, -5.062, -5.2438, -5.4297, -5.5175, -5.5576, -5.5179, -4.3363, -5.7045, -5.6891, -5.8222, -5.8956, -5.8769, -5.877, -5.8958, -5.9151, -5.9346, -5.9347, -5.9963, -6.0176, -5.9966, -6.062, -3.7828, -3.9421, -3.9915, -5.496, -4.7299, -5.5866, -3.5087, -4.3671, -3.4983, -4.9937, -3.2639, -4.1296, -2.8041, -4.8701, -5.1921, -3.7858, -5.0081, -4.4961, -5.0947, -4.8066, -3.8349, -4.4577, -4.7467, -4.9221, -2.9311, -3.9471, -4.1398, -4.8042, -4.8682, -5.2805, -5.3372, -5.3977, -5.4102, -5.4618, -5.4755, -5.5309, -5.7355, -5.7534, -5.8076, -5.7894, -5.8081, -5.8858, -5.8662, -5.9932, -6.1134, -6.2491, -6.2491, -6.2788, -6.2498, -6.2797, -6.2803, -6.3735, -6.4069, -6.3434, -5.6161, -5.3566, -4.4056, -5.6311, -4.0741, -5.0196, -4.9483, -4.1073, -4.4258, -3.0825, -4.5281, -3.693, -4.4083, -3.9384, -4.6368, -4.6794, -4.8921, -4.8684, -4.8848, -4.7241, -4.7104, -4.4906, -5.0706, -4.7873, -4.7104, -4.9398, -5.1127, -5.0663], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.141, 1.1406, 1.1406, 1.1406, 1.1402, 1.1399, 1.1387, 1.1386, 1.1381, 1.1381, 1.1378, 1.1378, 1.1364, 1.1362, 1.1357, 1.1355, 1.1354, 1.134, 1.1339, 1.1336, 1.1333, 1.1329, 1.1329, 1.1327, 1.1327, 1.1324, 1.1323, 1.1314, 1.1314, 1.1309, 1.0322, 1.0537, 1.0766, 0.9623, 1.0081, 0.909, 1.018, 0.8961, 0.7033, 0.9149, 0.99, 0.6673, 0.7529, 0.7071, 0.7438, 0.7627, 0.5737, 0.8894, 0.7235, 0.9407, 0.799, 0.8652, 0.676, 0.4332, 0.3815, 0.6542, 0.1365, 0.5691, 0.0023, 0.6324, -0.7634, 0.0204, 0.3047, 0.5698, -0.7446, 1.2737, 1.2737, 1.2735, 1.2733, 1.273, 1.2727, 1.2726, 1.2725, 1.2722, 1.2722, 1.2721, 1.2721, 1.2715, 1.2712, 1.2712, 1.2712, 1.2703, 1.27, 1.2698, 1.2696, 1.2695, 1.2694, 1.2691, 1.269, 1.2687, 1.2685, 1.2685, 1.2681, 1.268, 1.2676, 1.2669, 1.2521, 1.1078, 0.5692, 0.3877, 1.0148, 0.4188, 0.7824, 0.7833, 0.4742, -0.2079, -0.3553, -0.0141, -0.8226, 1.5845, 1.5839, 1.5824, 1.5818, 1.5815, 1.5813, 1.5798, 1.5798, 1.5798, 1.5791, 1.578, 1.5763, 1.5755, 1.5752, 1.5751, 1.575, 1.5735, 1.5733, 1.5716, 1.5709, 1.5709, 1.5708, 1.5707, 1.5704, 1.5703, 1.5703, 1.5693, 1.569, 1.569, 1.5681, 1.4722, 1.4529, 1.4219, 1.5102, 1.4084, 1.519, 1.1599, 1.2699, 0.999, 1.3361, 0.8695, 1.0026, 0.5057, 1.2443, 1.3475, 0.6417, 1.1813, 0.8084, 1.2395, 0.9867, 0.028, 0.5507, 0.2259, 0.6588, 1.6195, 1.6181, 1.6177, 1.6152, 1.6149, 1.6118, 1.6116, 1.6111, 1.611, 1.6107, 1.6102, 1.6097, 1.6074, 1.6068, 1.6067, 1.6066, 1.6063, 1.6056, 1.6053, 1.6036, 1.6012, 1.5991, 1.5991, 1.5984, 1.5984, 1.5975, 1.5969, 1.5962, 1.5955, 1.5945, 1.5549, 1.4954, 1.1869, 1.4467, 1.0224, 1.2638, 1.2399, 0.9808, 0.9444, 0.2273, 0.7831, 0.17, 0.5642, 0.195, 0.6677, 0.6724, 0.8432, 0.7125, 0.6438, 0.4196, 0.2981, -0.0632, 0.8246, -0.1187, -0.415, 0.1808, 0.5509, -0.3404]}, \"token.table\": {\"Topic\": [4, 3, 3, 3, 1, 2, 3, 4, 3, 4, 2, 2, 3, 4, 2, 3, 2, 4, 4, 2, 2, 1, 4, 1, 2, 3, 4, 3, 1, 2, 3, 2, 1, 1, 2, 1, 2, 4, 2, 4, 3, 1, 2, 4, 2, 4, 2, 3, 1, 3, 4, 1, 1, 2, 4, 1, 1, 4, 2, 1, 3, 3, 1, 4, 2, 1, 4, 4, 1, 3, 4, 1, 1, 1, 4, 1, 2, 3, 4, 1, 4, 1, 1, 2, 3, 4, 1, 2, 4, 1, 2, 4, 1, 1, 3, 3, 3, 2, 3, 1, 2, 1, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 4, 3, 4, 4, 3, 4, 2, 3, 3, 1, 3, 4, 2, 1, 2, 4, 4, 3, 3, 1, 2, 3, 3, 4, 1, 4, 2, 1, 4, 1, 1, 2, 4, 2, 2, 2, 1, 4, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 2, 3, 4, 3, 4, 4, 3, 1, 2, 3, 3, 4, 1, 3, 1, 1, 2, 3, 4, 3, 2, 1, 4, 2, 3, 4, 4, 4, 2, 2, 1, 4, 2, 4, 1, 2, 4, 3, 1, 2, 4, 4, 1, 2, 4, 1, 2, 3, 4, 1, 4, 1, 4, 4, 4, 1, 3, 4, 2, 2, 1, 2, 2, 1, 2, 1, 3, 4, 3, 4, 2, 2, 4, 2, 3, 1, 3, 1, 3, 4, 1, 1, 2, 3, 4, 2, 3, 1, 4, 1, 2, 4, 1, 3, 4, 2, 3, 2, 4, 1, 3, 4, 1, 2, 4, 4, 1, 2, 3, 4, 4, 3, 1, 2, 3, 4, 1, 2, 4, 1, 3, 4, 1, 1, 2, 4, 2, 3, 1, 2, 3, 4, 4, 2, 3, 4, 1, 4, 3, 4, 3, 4, 1, 4, 2, 4], \"Freq\": [0.9864979415610959, 0.9816127091746912, 0.9800961486845102, 0.9775821920234565, 0.11920949355904027, 0.2749765651428529, 0.257492506087527, 0.34809172119239756, 0.8363502722781657, 0.15809060024770205, 0.9977804119144906, 0.4248279061185809, 0.38888801818230184, 0.18615018879816342, 0.9921462875749569, 0.9983032097476114, 0.9969676728061672, 0.9865195526006684, 0.9865541215126659, 0.9947024922358534, 0.995143118544369, 0.9887457482013607, 0.9865603288711294, 0.669376564419174, 0.3311897984234241, 0.2947763477864128, 0.7015677077316624, 0.9823313012181387, 0.9929015791513034, 0.9959882220404901, 0.9882653531063873, 0.9971529393287538, 0.9820747188639593, 0.5626032496718308, 0.4379998453820965, 0.9929016773096351, 0.610830955374936, 0.3878660439072788, 0.9905593243929215, 0.9864097168663937, 0.9936726329581825, 0.597324069303113, 0.18691773597240272, 0.21129831022967263, 0.1565917393137808, 0.8351559430068308, 0.28878347241028873, 0.7120006302529532, 0.36357423979745335, 0.5574805010227618, 0.07644381452151583, 0.9843561525581336, 0.7542470313828654, 0.07157088618961496, 0.1706690362983126, 0.9949116761869455, 0.7718444752996874, 0.22342866390254107, 0.9996498271371376, 0.9909446840958164, 0.9973922504048736, 0.9800969046325266, 0.995765975827831, 0.9868052000984755, 0.9925860514105108, 0.929522770552926, 0.05996921100341458, 0.9868187861758315, 0.08340181733836034, 0.7289936626612238, 0.185337371863023, 0.9935251684994838, 0.9850380097039233, 0.7921548610744265, 0.20537348250077722, 0.6112051113877127, 0.07540842283354898, 0.11906593078981417, 0.19447435362336316, 0.11452352873338563, 0.8849545402125253, 0.9952942051038864, 0.9922258005929065, 0.11257407475708994, 0.1983447983815394, 0.6861657889955958, 0.10486220726648827, 0.7703339072268947, 0.1209948545382557, 0.6808783953838374, 0.0712215894752968, 0.245002267795021, 0.9892233447616825, 0.9943818560889268, 0.9958530736109676, 0.9925961731191821, 0.9899040005847025, 0.0607309815574845, 0.9231109196737644, 0.8572369937055239, 0.1417478493528819, 0.547873994894005, 0.45189606878118666, 0.6198269136824285, 0.09316035776790008, 0.14657229622149612, 0.1403616057036361, 0.6119204602854583, 0.1709777756679957, 0.21597192715957353, 0.151197759481527, 0.19566768874079962, 0.5563682260660111, 0.09684562372019376, 0.9996676023163971, 0.9868639796630644, 0.9935258129066105, 0.9934612929551534, 0.9993068641502073, 0.9863952316043483, 0.9863857555775466, 0.7846488252141932, 0.20568464350274968, 0.974690335643663, 0.02016600694435165, 0.9823229790000728, 0.25643419716434684, 0.5489858868870523, 0.195034459815137, 0.9965065814188334, 0.46608849999640933, 0.1003539832528154, 0.4326371722454708, 0.9865328855987069, 0.9887514889387693, 0.9936760499983109, 0.9932197863642296, 0.9976184913220221, 0.9978929600381067, 0.9747337367129214, 0.9867541641037125, 0.7049658453894714, 0.2894561749281273, 0.9943733818012566, 0.4897027695690345, 0.5086284804702532, 0.9949056941870249, 0.6419733718141853, 0.22691134274186928, 0.13081721538855098, 0.9953731693363761, 0.9973611918078306, 0.9955717251113579, 0.8144494214835537, 0.18540312033771955, 0.9865148652532731, 0.060790781940044905, 0.4936630740303647, 0.21067150293015563, 0.23425413385517305, 0.982874116587401, 0.5629871761385946, 0.05737448928800964, 0.1613657511225271, 0.21874024041053675, 0.4120329012577695, 0.33969354770849025, 0.24836511385252527, 0.8754475939651988, 0.12367819194522199, 0.9863663316880781, 0.995181580258035, 0.9945292155986767, 0.9898407394571065, 0.006386069286820042, 0.9958942719770619, 0.9966286178413638, 0.9907433604032521, 0.9944955883602696, 0.9941082714206045, 0.31798063330114845, 0.059312449734929246, 0.3558746984095755, 0.2669060238071816, 0.9766758181324716, 0.9959450584349014, 0.9942139500241701, 0.0033362884228998997, 0.27654026665726916, 0.19625438278902974, 0.5281027027777527, 0.9867548419704174, 0.9976611710375773, 0.9991978359531292, 0.9973778223873642, 0.6246800312791465, 0.3733294861490757, 0.8457776127380714, 0.15209158825553037, 0.9932197771466047, 0.3515992387393249, 0.6470607838984216, 0.9775816522548499, 0.8706102902448879, 0.014756106614320134, 0.11313015070978769, 0.9864275035245821, 0.9141461141999396, 0.08624019945282449, 0.9866164797521612, 0.564652526494066, 0.1904851896606488, 0.11701233079154141, 0.12925780726972597, 0.9962100109131451, 0.9863600544991961, 0.8795522943968097, 0.11501837695958281, 0.986897876582486, 0.9867747783626389, 0.9918777391934548, 0.8496938004298, 0.1506724471692378, 0.9985983501775102, 0.9957400493231598, 0.9911287448208794, 0.9996256011030742, 0.9952580312382864, 0.9970244753980794, 0.9940187446493943, 0.9828774525577995, 0.9843216172352925, 0.9930067638659444, 0.9975618021989219, 0.9863828723026579, 0.9925710996061416, 0.4498120331787999, 0.5505699286108511, 0.9905567761030619, 0.981611791455184, 0.05366639512167735, 0.9391619146293536, 0.429633862010683, 0.1912563643789492, 0.3769690660222767, 0.9892200840376587, 0.004691394766164928, 0.16654451419885496, 0.6532767211884662, 0.17592730373118481, 0.10541887608906303, 0.8918436917134733, 0.6566711296096235, 0.3426110241441514, 0.6451075065933725, 0.11796251549135954, 0.23776819528727156, 0.6752549771386607, 0.17386804800576292, 0.15162911163293277, 0.9969670680005732, 0.9949291738099187, 0.9962050443145609, 0.9865243692958507, 0.1985922688598491, 0.3971845377196982, 0.4030254868038114, 0.789737729895579, 0.08682980276338827, 0.12197519911999781, 0.9868462036259261, 0.1483376356234638, 0.1229279480398149, 0.48896479890697325, 0.24036190957505707, 0.9866898928347355, 0.9978320074164896, 0.09925274244951149, 0.13026922446498382, 0.7071757899527694, 0.06823626043403914, 0.7796490741200056, 0.07200580620853556, 0.1489775300866253, 0.15506044075195927, 0.460751023948679, 0.38543595272629877, 0.9892230751392164, 0.31355298698778095, 0.2249401863173211, 0.4601049265581568, 0.9986742272147809, 0.9808682215685945, 0.32441853519369984, 0.14334772485303016, 0.231996975748983, 0.3017846839011161, 0.9867754384151107, 0.999437302908649, 0.9875086505406484, 0.008127643214326324, 0.8935537388295365, 0.10548898305626472, 0.6655243732682883, 0.32739505459165796, 0.7781703592301342, 0.21615843311948174, 0.8313686340674613, 0.16684906842876385, 0.05729331993893042, 0.9310164490076193], \"Term\": [\"14k\", \"adventure\", \"ali\", \"along\", \"always\", \"always\", \"always\", \"always\", \"amazing\", \"amazing\", \"bag\", \"beautiful\", \"beautiful\", \"beautiful\", \"belt\", \"birthday\", \"black\", \"bleach\", \"blonde\", \"blouse\", \"blue\", \"body\", \"break\", \"buy\", \"buy\", \"channel\", \"channel\", \"chari\", \"check\", \"chic\", \"chicken\", \"classic\", \"clean\", \"clothes\", \"clothes\", \"coffee\", \"color\", \"color\", \"com\", \"comment\", \"congrats\", \"could\", \"could\", \"could\", \"cut\", \"cut\", \"cute\", \"cute\", \"day\", \"day\", \"day\", \"diet\", \"different\", \"different\", \"different\", \"dog\", \"dont\", \"dont\", \"dress\", \"dry\", \"dubai\", \"easter\", \"eat\", \"edit\", \"elegant\", \"end\", \"end\", \"energy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enough\", \"etc\", \"even\", \"even\", \"every\", \"every\", \"every\", \"every\", \"experience\", \"experience\", \"eye\", \"fall\", \"fashion\", \"fashion\", \"fashion\", \"favorite\", \"favorite\", \"favorite\", \"feel\", \"feel\", \"feel\", \"foundation\", \"free\", \"fun\", \"gerald\", \"gerry\", \"gift\", \"gift\", \"girl\", \"girl\", \"give\", \"give\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"gorgeous\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"hair\", \"hairdresser\", \"hand\", \"happen\", \"happy\", \"heidi\", \"helen\", \"hello\", \"hello\", \"hermes\", \"hermes\", \"holiday\", \"hope\", \"hope\", \"hope\", \"http\", \"im\", \"im\", \"im\", \"inspire\", \"interview\", \"irene\", \"issue\", \"jean\", \"jo\", \"joy\", \"k18\", \"keep\", \"keep\", \"knit\", \"know\", \"know\", \"learn\", \"like\", \"like\", \"like\", \"lily\", \"lilysilk\", \"link\", \"live\", \"live\", \"london\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"lovely\", \"lovely\", \"luxury\", \"lydia\", \"makeup\", \"mel\", \"mel\", \"michael\", \"money\", \"month\", \"mother\", \"move\", \"much\", \"much\", \"much\", \"much\", \"myrtle\", \"navy\", \"need\", \"need\", \"new\", \"new\", \"new\", \"olaplex\", \"old\", \"outfit\", \"pant\", \"people\", \"people\", \"piece\", \"piece\", \"plant\", \"please\", \"please\", \"podcast\", \"product\", \"product\", \"product\", \"purple\", \"put\", \"put\", \"quiet\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommendation\", \"right\", \"right\", \"safe\", \"salon\", \"sell\", \"share\", \"share\", \"shirt\", \"shoe\", \"side\", \"silk\", \"size\", \"skin\", \"skirt\", \"sleep\", \"smile\", \"sorry\", \"stephanie\", \"story\", \"striped\", \"style\", \"style\", \"summer\", \"sunday\", \"sweet\", \"sweet\", \"take\", \"take\", \"take\", \"talk\", \"thank\", \"thank\", \"thank\", \"thank\", \"thanks\", \"thanks\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"top\", \"trip\", \"trouser\", \"ur\", \"us\", \"us\", \"us\", \"use\", \"use\", \"use\", \"victoria\", \"video\", \"video\", \"video\", \"video\", \"videos\", \"vlog\", \"wait\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"watch\", \"watch\", \"watch\", \"water\", \"way\", \"way\", \"way\", \"wear\", \"weekend\", \"well\", \"well\", \"well\", \"well\", \"whatever\", \"white\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"wow\", \"wow\", \"xx\", \"xx\", \"year\", \"year\", \"youtube\", \"youtube\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 1, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el33501382569467599362910955856\", ldavis_el33501382569467599362910955856_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el33501382569467599362910955856\", ldavis_el33501382569467599362910955856_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el33501382569467599362910955856\", ldavis_el33501382569467599362910955856_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding dominant Topic:\n",
        "Each document contains several topics. One of the topics is dominant."
      ],
      "metadata": {
        "id": "gga8DlSBUWG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_news_topic_weights = lda_reviews.transform(bow_a_corpus)"
      ],
      "metadata": {
        "id": "PgCJKr2AUZvt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
        "doc_names = [\"Doc_\" + str(i) for i in range(len(NORM_reviews))]\n",
        "topic_names = [\"Topic_\" + str(i) for i in range(4)]\n",
        "\n",
        "#convert to dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_news_topic_weights, 4), columns=topic_names, index=doc_names)"
      ],
      "metadata": {
        "id": "h8NCDWOoUby7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_document_topic.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpADhUZ5btZn",
        "outputId": "0ed7015b-ed86-4b79-b7b2-55034317bf10"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Topic_0  Topic_1  Topic_2  Topic_3\n",
            "Doc_0   0.5536   0.0139   0.0937   0.3388\n",
            "Doc_1   0.0312   0.0309   0.0283   0.9096\n",
            "Doc_2   0.3389   0.0129   0.0133   0.6349\n",
            "Doc_3   0.3124   0.0193   0.1657   0.5026\n",
            "Doc_4   0.6457   0.0216   0.3121   0.0206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "\n",
        "#add dominant_topic as a column to df_document_topic\n",
        "df_document_topic['dominant_topic'] = dominant_topic"
      ],
      "metadata": {
        "id": "62wtTpR4Ud_C"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_document_topic.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rldlOeP1bwse",
        "outputId": "749bb482-698e-4b17-fc9e-d4ea3cd16cc4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Topic_0  Topic_1  Topic_2  Topic_3  dominant_topic\n",
            "Doc_0   0.5536   0.0139   0.0937   0.3388               0\n",
            "Doc_1   0.0312   0.0309   0.0283   0.9096               3\n",
            "Doc_2   0.3389   0.0129   0.0133   0.6349               3\n",
            "Doc_3   0.3124   0.0193   0.1657   0.5026               3\n",
            "Doc_4   0.6457   0.0216   0.3121   0.0206               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Model Evaluation: Log-likelihood, Perplexity and Coherence Scores**\n",
        "\n",
        "Log-likelihood, Perplexity and Coherence Score are **measures of performance** for a topic model. They are used for comparing and discriminating between topic models estimated on the same data. Log-likelihood, perplexity and coherence scores **do not have** a baseline or a threshold values and therefore are useful only for comparing models.\n",
        "\n",
        "How we specify different models: We set **different number of topics** and also play with the **parameters of the Dirichlet distributions**.\n",
        "\n",
        "#### **Coherence Score**\n",
        "\n",
        "We will use a function **CoherenceModel()** from the **gensim** module (you can also explore that package as it can be used to estimate an LDA model). The sklearn module does not have the functionality to compute the coherence score."
      ],
      "metadata": {
        "id": "4fKl04Wwb7RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "mo4JlLWNcF8b"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the corpus\n",
        "reviews_corpus_tokenized = [tokenize_text(NORM_reviews[doc_id]) for doc_id in range(len(NORM_reviews))]\n",
        "\n",
        "#Dictionary of the corpus:\n",
        "reviews_dictionary = Dictionary(reviews_corpus_tokenized)\n",
        "\n",
        "#Bag-of-words representation for each document of the corpus:\n",
        "reviews_corpus_bow = [reviews_dictionary.doc2bow(doc) for doc in reviews_corpus_tokenized]\n",
        "\n",
        "#top 20 words for each topic (using the function defined in session prep)\n",
        "topic_topwords = get_topic_words(vectorizer = bow_vectorizer, lda_model = lda_reviews, n_words=20)"
      ],
      "metadata": {
        "id": "pNDP15axcIO9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = CoherenceModel(topics=topic_topwords,\n",
        "                    corpus = reviews_corpus_bow ,\n",
        "                    dictionary = reviews_dictionary, coherence='u_mass')\n",
        "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 4))  # get coherence value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mljNNdpcKqb",
        "outputId": "d002d1b9-3a81-41fd-e023-1774c0f6fef6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score for the model:  -2.6368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see coherence scores by topic:\n",
        "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMIuI3uAcNin",
        "outputId": "3d6088a1-d8eb-4c7e-d5ad-4eeadabe9915"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score by topic (higher values are better):  [-2.8516 -2.421  -2.5533 -2.7212]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log-Likelihood Score\n",
        "## To compute the log-likelihood score we use the .score attribute of our defined and fitted LDA function:\n",
        "print(\"Log-Likelihood (higher values are better): \", lda_reviews.score(bow_a_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNCADrSWcQKh",
        "outputId": "57cc1a04-008b-488c-dc4c-e022603a14d2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Likelihood (higher values are better):  -560858.5434673639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity Score\n",
        "## To compute the Perplexity score we use the .perplexity attribute of our defined and fitted LDA function:\n",
        "print(\"Perplexity (lower values are better): \", lda_reviews.perplexity(bow_a_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cvi60IqcSto",
        "outputId": "e64d64a4-8a6c-43ae-df9b-344e64257fc4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (lower values are better):  480.07024023324266\n"
          ]
        }
      ]
    }
  ]
}